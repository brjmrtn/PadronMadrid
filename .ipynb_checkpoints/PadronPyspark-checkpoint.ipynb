{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0addfd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerias\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import lit, trim, col, length, round\n",
    "\n",
    "# Creamos sesion\n",
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession\n",
    "        .builder\n",
    "        .appName(\"Padron\")\n",
    "        .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4a3ab995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+---------------+-----------+----------+----------------+-----------+------------+----------------+----------------+------------------+------------------+\n",
      "|COD_DISTRITO|DESC_DISTRITO|COD_DIST_BARRIO|DESC_BARRIO|COD_BARRIO|COD_DIST_SECCION|COD_SECCION|COD_EDAD_INT|EspanolesHombres|EspanolesMujeres|ExtranjerosHombres|ExtranjerosMujeres|\n",
      "+------------+-------------+---------------+-----------+----------+----------------+-----------+------------+----------------+----------------+------------------+------------------+\n",
      "|           1|       CENTRO|            101|    PALACIO|         1|            1001|          1|           0|               2|               3|                 1|                 0|\n",
      "|           1|       CENTRO|            101|    PALACIO|         1|            1001|          1|           1|               7|               0|                 1|                 0|\n",
      "|           1|       CENTRO|            101|    PALACIO|         1|            1001|          1|           2|               2|               3|                 0|                 5|\n",
      "|           1|       CENTRO|            101|    PALACIO|         1|            1001|          1|           3|               3|               1|                 0|                 0|\n",
      "|           1|       CENTRO|            101|    PALACIO|         1|            1001|          1|           4|               2|               0|                 1|                 3|\n",
      "|           1|       CENTRO|            101|    PALACIO|         1|            1001|          1|           5|               2|               3|                 0|                 0|\n",
      "|           1|       CENTRO|            101|    PALACIO|         1|            1001|          1|           6|               1|               0|                 2|                 1|\n",
      "|           1|       CENTRO|            101|    PALACIO|         1|            1001|          1|           7|               1|               2|                 0|                 0|\n",
      "|           1|       CENTRO|            101|    PALACIO|         1|            1001|          1|           8|               3|               2|                 1|                 2|\n",
      "|           1|       CENTRO|            101|    PALACIO|         1|            1001|          1|           9|               3|               0|                 0|                 1|\n",
      "+------------+-------------+---------------+-----------+----------+----------------+-----------+------------+----------------+----------------+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el csv con la estructura correcta, eliminando \"\", sustituyendo \"\" como nulos por 0 y quitando espacios innecesarios\n",
    "file = 'padron.csv'\n",
    "\n",
    "padron = (spark.read.format('csv')\n",
    "         .option('header', 'true')\n",
    "         .option('inferSchema', 'true')\n",
    "         .option('delimiter', ';')\n",
    "         .option('quotes', '\\\"')\n",
    "         .option('emptyValue', 0)\n",
    "         .load(file))\n",
    "# Para eliminar los espacios en blanco innecesarios:\n",
    "padron_df = padron.select([(trim(i[0])).alias(i[0]) if i[1] == \"string\" else i[0] for i in padron.select(\"*\").dtypes])\n",
    "\n",
    "\n",
    "padron_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1f15630c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         DESC_BARRIO|\n",
      "+--------------------+\n",
      "|        VALDEFUENTES|\n",
      "|            ABRANTES|\n",
      "|       LOS JERONIMOS|\n",
      "|          NI�O JESUS|\n",
      "|            VALVERDE|\n",
      "|              CORTES|\n",
      "|   PALOMERAS SURESTE|\n",
      "|CIUDAD UNIVERSITARIA|\n",
      "|      CUATRO VIENTOS|\n",
      "|           TRAFALGAR|\n",
      "|              HELLIN|\n",
      "|    ALAMEDA DE OSUNA|\n",
      "|          PRADOLONGO|\n",
      "|            MOSCARDO|\n",
      "|          VALDEZARZA|\n",
      "|           RECOLETOS|\n",
      "|             HORCAJO|\n",
      "|        VISTA ALEGRE|\n",
      "|             EL VISO|\n",
      "|    PUERTA DEL ANGEL|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enumerar los distintos barrios\n",
    "neighborhood = (padron_df.select('DESC_BARRIO')\n",
    "               .distinct())\n",
    "neighborhood.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3f8c5898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|Total_Barrios|\n",
      "+-------------+\n",
      "|          131|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contar a traves de las views, el número de barrios\n",
    "padron_df.createOrReplaceTempView('padron')\n",
    "\n",
    "spark.sql('select count(distinct DESC_BARRIO) AS Total_Barrios FROM padron').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3f8fa80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+\n",
      "|      Desc_Distrito|Longitud|\n",
      "+-------------------+--------+\n",
      "|         ARGANZUELA|      10|\n",
      "|FUENCARRAL-EL PARDO|      19|\n",
      "|              USERA|       5|\n",
      "|          SALAMANCA|       9|\n",
      "| PUENTE DE VALLECAS|      18|\n",
      "|  VILLA DE VALLECAS|      17|\n",
      "|           CHAMBERI|       8|\n",
      "|          VICALVARO|       9|\n",
      "|             RETIRO|       6|\n",
      "|             CENTRO|       6|\n",
      "|SAN BLAS-CANILLEJAS|      19|\n",
      "|          CHAMARTIN|       9|\n",
      "|             LATINA|       6|\n",
      "|          MORATALAZ|       9|\n",
      "|            BARAJAS|       7|\n",
      "|             TETUAN|       6|\n",
      "|      CIUDAD LINEAL|      13|\n",
      "|          HORTALEZA|       9|\n",
      "|         VILLAVERDE|      10|\n",
      "|        CARABANCHEL|      11|\n",
      "+-------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crea una nueva columna que muestre la longitud de los campos de la columna DESC_DISTRITO y que se llame \"longitud\"\n",
    "padron_lon = (padron_df\n",
    "                 .withColumn(\"Longitud\", length(col(\"DESC_DISTRITO\")))\n",
    "                 .select(\"Desc_Distrito\", \"Longitud\")\n",
    "                 .distinct()\n",
    "                 .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "36dd7e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|      DESC_DISTRITO|Cinco|\n",
      "+-------------------+-----+\n",
      "|          VICALVARO|    5|\n",
      "|             TETUAN|    5|\n",
      "|           CHAMBERI|    5|\n",
      "|             RETIRO|    5|\n",
      "|  VILLA DE VALLECAS|    5|\n",
      "|         VILLAVERDE|    5|\n",
      "|        CARABANCHEL|    5|\n",
      "|              USERA|    5|\n",
      "|            BARAJAS|    5|\n",
      "|          CHAMARTIN|    5|\n",
      "|    MONCLOA-ARAVACA|    5|\n",
      "|      CIUDAD LINEAL|    5|\n",
      "|          MORATALAZ|    5|\n",
      "|         ARGANZUELA|    5|\n",
      "|          SALAMANCA|    5|\n",
      "|          HORTALEZA|    5|\n",
      "|SAN BLAS-CANILLEJAS|    5|\n",
      "|             CENTRO|    5|\n",
      "|FUENCARRAL-EL PARDO|    5|\n",
      "| PUENTE DE VALLECAS|    5|\n",
      "+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear una columna que muestre el valor 5 para cada uno de los registro de la tabla\n",
    "padron5 = (padron_df\n",
    "          .withColumn('Cinco', lit('5'))\n",
    "          .select('DESC_DISTRITO', 'Cinco')\n",
    "          .distinct())\n",
    "padron5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "31fa526f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|      DESC_DISTRITO|\n",
      "+-------------------+\n",
      "|          VICALVARO|\n",
      "|             TETUAN|\n",
      "|           CHAMBERI|\n",
      "|             RETIRO|\n",
      "|  VILLA DE VALLECAS|\n",
      "|         VILLAVERDE|\n",
      "|        CARABANCHEL|\n",
      "|              USERA|\n",
      "|            BARAJAS|\n",
      "|          CHAMARTIN|\n",
      "|    MONCLOA-ARAVACA|\n",
      "|      CIUDAD LINEAL|\n",
      "|          MORATALAZ|\n",
      "|         ARGANZUELA|\n",
      "|          SALAMANCA|\n",
      "|          HORTALEZA|\n",
      "|SAN BLAS-CANILLEJAS|\n",
      "|             CENTRO|\n",
      "|FUENCARRAL-EL PARDO|\n",
      "| PUENTE DE VALLECAS|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Borra esta columna\n",
    "drop_cinco = padron5.drop('Cinco')\n",
    "drop_cinco.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ab64ea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Particiona el dataframe por las variables DESC_DISTRITO y DESC_BARRIO\n",
    "partition = (padron_df\n",
    "            .repartition(col('DESC_BARRIO'), col('DESC_DISTRITO')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "114e2d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238196"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Almacénalo en caché. Consulta en el puerto 4040 (UI de Spark) de tu usuario local el estado\n",
    "# de los rdds almacenados.\n",
    "partition.cache()\n",
    "partition.count()\n",
    "partition.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "55a61f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------+---------------+---------------+-------------------+-------------------+\n",
      "|      DESC_DISTRITO|      DESC_BARRIO|Total Españoles|Total Españolas|Total Extranjeros H|Total Extranjeras F|\n",
      "+-------------------+-----------------+---------------+---------------+-------------------+-------------------+\n",
      "|         ARGANZUELA|          ACACIAS|          15399|          18073|               1355|               1507|\n",
      "|FUENCARRAL-EL PARDO|         VALVERDE|          26922|          29105|               3675|               4441|\n",
      "|FUENCARRAL-EL PARDO|   FUENTELARREINA|           1445|           1679|                 72|                171|\n",
      "|          MORATALAZ|          PAVONES|           3584|           4321|                419|                478|\n",
      "|FUENCARRAL-EL PARDO|        EL GOLOSO|           8947|           9076|                551|                630|\n",
      "|          HORTALEZA|         CANILLAS|          16770|          19155|               1764|               2248|\n",
      "|      CIUDAD LINEAL|SAN JUAN BAUTISTA|           5182|           5900|                620|                694|\n",
      "|          CHAMARTIN|      PROSPERIDAD|          14490|          17804|               1763|               2280|\n",
      "|         ARGANZUELA|          LEGAZPI|           8897|           9201|                736|                802|\n",
      "|      CIUDAD LINEAL|      COSTILLARES|           9778|          10908|                490|                711|\n",
      "|             LATINA| PUERTA DEL ANGEL|          15120|          17686|               4260|               4854|\n",
      "|           CHAMBERI|       GAZTAMBIDE|           8921|          11007|               1286|               1793|\n",
      "|             LATINA|       CAMPAMENTO|           7102|           8102|               1884|               2330|\n",
      "|        CARABANCHEL|       SAN ISIDRO|          14537|          16548|               4183|               4489|\n",
      "|          SALAMANCA|             GOYA|          10913|          13876|               2067|               2951|\n",
      "|             CENTRO|      UNIVERSIDAD|          12410|          12495|               4243|               4309|\n",
      "| PUENTE DE VALLECAS|         NUMANCIA|          17151|          19383|               5446|               5749|\n",
      "|             RETIRO|       NI�O JESUS|           6557|           7722|                356|                573|\n",
      "|          HORTALEZA|          PALOMAS|           3034|           3121|                374|                428|\n",
      "|             CENTRO|              SOL|           2872|           2595|               1427|               1402|\n",
      "+-------------------+-----------------+---------------+---------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lanza una consulta contra el DF resultante en la que muestre el número total de \n",
    "#\"espanoleshombres\", \"espanolesmujeres\", extranjeroshombres\" y \"extranjerosmujeres\" \n",
    "#para cada barrio de cada distrito. Las columnas distrito y barrio deben ser las primeras en \n",
    "#aparecer en el show. Los resultados deben estar ordenados en orden de más a menos \n",
    "#según la columna \"extranjerosmujeres\" y desempatarán por la columna \n",
    "#\"extranjeroshombres\".\n",
    "(partition.select('DESC_DISTRITO', 'DESC_BARRIO', 'EspanolesHombres', 'EspanolesMujeres', 'ExtranjerosHombres', 'ExtranjerosMujeres')\n",
    "         .groupBy('DESC_DISTRITO', 'DESC_BARRIO')\n",
    "         .sum('EspanolesHombres', 'EspanolesMujeres', 'ExtranjerosHombres', 'ExtranjerosMujeres')\n",
    "         .withColumnRenamed('sum(EspanolesHombres)', 'Total Españoles')\n",
    "         .withColumnRenamed('sum(EspanolesMujeres)', 'Total Españolas')\n",
    "         .withColumnRenamed('sum(ExtranjerosHombres)', 'Total Extranjeros H')\n",
    "         .withColumnRenamed('sum(ExtranjerosMujeres)', 'Total Extranjeras F')\n",
    "         .show())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ae4cc73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[COD_DISTRITO: int, DESC_DISTRITO: string, COD_DIST_BARRIO: int, DESC_BARRIO: string, COD_BARRIO: int, COD_DIST_SECCION: int, COD_SECCION: int, COD_EDAD_INT: int, EspanolesHombres: int, EspanolesMujeres: int, ExtranjerosHombres: int, ExtranjerosMujeres: int]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminar el registro caché\n",
    "partition.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c65702d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------+---------+\n",
      "|           DISTRITO|           BARRIO|Españoles|\n",
      "+-------------------+-----------------+---------+\n",
      "|         ARGANZUELA|          ACACIAS|    15399|\n",
      "|FUENCARRAL-EL PARDO|         VALVERDE|    26922|\n",
      "|FUENCARRAL-EL PARDO|   FUENTELARREINA|     1445|\n",
      "|          MORATALAZ|          PAVONES|     3584|\n",
      "|FUENCARRAL-EL PARDO|        EL GOLOSO|     8947|\n",
      "|          HORTALEZA|         CANILLAS|    16770|\n",
      "|      CIUDAD LINEAL|SAN JUAN BAUTISTA|     5182|\n",
      "|          CHAMARTIN|      PROSPERIDAD|    14490|\n",
      "|      CIUDAD LINEAL|      COSTILLARES|     9778|\n",
      "|         ARGANZUELA|          LEGAZPI|     8897|\n",
      "|             LATINA|       CAMPAMENTO|     7102|\n",
      "|           CHAMBERI|       GAZTAMBIDE|     8921|\n",
      "|             LATINA| PUERTA DEL ANGEL|    15120|\n",
      "|        CARABANCHEL|       SAN ISIDRO|    14537|\n",
      "|          SALAMANCA|             GOYA|    10913|\n",
      "|             CENTRO|      UNIVERSIDAD|    12410|\n",
      "| PUENTE DE VALLECAS|         NUMANCIA|    17151|\n",
      "|             RETIRO|       NI�O JESUS|     6557|\n",
      "|          HORTALEZA|          PALOMAS|     3034|\n",
      "|             CENTRO|              SOL|     2872|\n",
      "+-------------------+-----------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Crea un nuevo DataFrame a partir del original que muestre únicamente una columna con \n",
    "#DESC_BARRIO, otra con DESC_DISTRITO y otra con el número total de \"espanoleshombres\" \n",
    "#residentes en cada distrito de cada barrio. Únelo (con un join) con el DataFrame original a \n",
    "#través de las columnas en común.\n",
    "\n",
    "espanoles = (padron_df.select('DESC_BARRIO', 'DESC_DISTRITO', 'EspanolesHombres')\n",
    "                     .groupBy('DESC_BARRIO', 'DESC_DISTRITO')\n",
    "                     .sum('EspanolesHombres')\n",
    "                     .withColumnRenamed('sum(EspanolesHombres)', 'Españoles')\n",
    "                     .withColumnRenamed('DESC_BARRIO', 'BARRIO')\n",
    "                     .withColumnRenamed('DESC_DISTRITO', 'DISTRITO'))\n",
    "        \n",
    "(espanoles.join(padron_df,\n",
    "               (padron_df.DESC_BARRIO == espanoles.BARRIO) & \n",
    "               (padron_df.DESC_DISTRITO == espanoles.DISTRITO))\n",
    ".select('DISTRITO', 'BARRIO', 'Españoles')\n",
    ".distinct()\n",
    ".show())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e1809e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----------------------+\n",
      "|      DESC_BARRIO|      DESC_DISTRITO|Total Españoles Hombres|\n",
      "+-----------------+-------------------+-----------------------+\n",
      "|       MIRASIERRA|FUENCARRAL-EL PARDO|                  16230|\n",
      "|       CASTELLANA|          SALAMANCA|                   6106|\n",
      "|      EL SALVADOR|SAN BLAS-CANILLEJAS|                   4867|\n",
      "|     VALDEFUENTES|          HORTALEZA|                  28743|\n",
      "|    CASA DE CAMPO|    MONCLOA-ARAVACA|                   5421|\n",
      "|       MARROQUINA|          MORATALAZ|                  11357|\n",
      "|    BELLAS VISTAS|             TETUAN|                  10193|\n",
      "|     EL CA�AVERAL|          VICALVARO|                   3934|\n",
      "|         JUSTICIA|             CENTRO|                   7048|\n",
      "|      UNIVERSIDAD|             CENTRO|                  12410|\n",
      "|          ATALAYA|      CIUDAD LINEAL|                    607|\n",
      "|       BERRUGUETE|             TETUAN|                   8628|\n",
      "|CASCO H.VICALVARO|          VICALVARO|                  13331|\n",
      "|         CASTILLA|          CHAMARTIN|                   7149|\n",
      "|          LEGAZPI|         ARGANZUELA|                   8897|\n",
      "|           HELLIN|SAN BLAS-CANILLEJAS|                   3596|\n",
      "|   HISPANOAMERICA|          CHAMARTIN|                  13226|\n",
      "|    SANTA EUGENIA|  VILLA DE VALLECAS|                  10330|\n",
      "|      EMBAJADORES|             CENTRO|                  16640|\n",
      "|      LOS ANGELES|         VILLAVERDE|                  12491|\n",
      "+-----------------+-------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Repite la función anterior utilizando funciones de ventana. (over(Window.partitionBy.....)).\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "w = Window.partitionBy('DESC_DISTRITO', 'DESC_BARRIO')\n",
    "\n",
    "padron_w = (padron_df\n",
    "           .withColumn('Total Españoles Hombres', F.sum('EspanolesHombres').over(w))\n",
    "           .select('DESC_BARRIO', 'DESC_DISTRITO', 'Total Españoles Hombres')\n",
    "           .distinct())\n",
    "\n",
    "padron_w.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7b5bf75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+------------------+-----------------+\n",
      "|COD_EDAD_INT|            CENTRO|            RETIRO|          BARAJAS|\n",
      "+------------+------------------+------------------+-----------------+\n",
      "|           0|2.1621621621621623| 3.161290322580645|4.866666666666666|\n",
      "|           1| 2.209090909090909|3.6808510638297873|6.419354838709677|\n",
      "|           2| 2.009009009009009| 3.648936170212766|5.806451612903226|\n",
      "|           3| 2.081818181818182| 4.118279569892473|6.580645161290323|\n",
      "|           4| 2.054054054054054| 4.457446808510638|7.451612903225806|\n",
      "|           5| 2.081081081081081|               4.5|7.838709677419355|\n",
      "|           6|2.3363636363636364| 4.542553191489362|8.290322580645162|\n",
      "|           7| 2.190909090909091| 4.627659574468085|7.870967741935484|\n",
      "|           8|2.0458715596330275| 4.553191489361702| 8.64516129032258|\n",
      "|           9|2.3518518518518516| 4.574468085106383|7.903225806451613|\n",
      "|          10|2.2844036697247705| 4.494623655913978| 8.67741935483871|\n",
      "|          11| 2.290909090909091|               4.5| 8.64516129032258|\n",
      "|          12|2.3394495412844036|4.6063829787234045|8.483870967741936|\n",
      "|          13|2.3873873873873874| 4.531914893617022|9.193548387096774|\n",
      "|          14| 2.272727272727273| 4.212765957446808|8.258064516129032|\n",
      "|          15|2.5137614678899083| 4.617021276595745| 8.96774193548387|\n",
      "|          16|               2.3| 4.585106382978723|8.741935483870968|\n",
      "|          17|2.4234234234234235| 4.319148936170213|7.935483870967742|\n",
      "|          18|2.6486486486486487|  4.75531914893617| 8.35483870967742|\n",
      "|          19|2.5636363636363635|4.3936170212765955|7.161290322580645|\n",
      "+------------+------------------+------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mediante una función Pivot muestra una tabla (que va a ser una tabla de contingencia) que\n",
    "#contenga los valores totales ()la suma de valores (avg) de espanolesmujeres para cada distrito y \n",
    "#en cada rango de edad (COD_EDAD_INT). Los distritos incluidos deben ser únicamente \n",
    "#CENTRO, BARAJAS y RETIRO y deben figurar como columnas.\n",
    "\n",
    "pivot_df = (padron_df.groupBy('COD_EDAD_INT').pivot('DESC_DISTRITO', ['CENTRO', 'RETIRO', 'BARAJAS'])\n",
    "           .avg('EspanolesMujeres')\n",
    "           .orderBy('COD_EDAD_INT'))\n",
    "\n",
    "pivot_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d1c6452f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+------------------+-----------------+------------------+-----------------+-----------------+\n",
      "|COD_EDAD_INT|            CENTRO|            RETIRO|          BARAJAS|Barajas Porcentaje|Centro Porcentaje|Retiro Porcentaje|\n",
      "+------------+------------------+------------------+-----------------+------------------+-----------------+-----------------+\n",
      "|           0|2.1621621621621623| 3.161290322580645|4.866666666666666|             47.76|            21.22|            31.02|\n",
      "|           1| 2.209090909090909|3.6808510638297873|6.419354838709677|             52.15|            17.95|             29.9|\n",
      "|           2| 2.009009009009009| 3.648936170212766|5.806451612903226|             50.65|            17.52|            31.83|\n",
      "|           3| 2.081818181818182| 4.118279569892473|6.580645161290323|             51.49|            16.29|            32.22|\n",
      "|           4| 2.054054054054054| 4.457446808510638|7.451612903225806|             53.37|            14.71|            31.92|\n",
      "|           5| 2.081081081081081|               4.5|7.838709677419355|             54.36|            14.43|            31.21|\n",
      "|           6|2.3363636363636364| 4.542553191489362|8.290322580645162|             54.65|             15.4|            29.95|\n",
      "|           7| 2.190909090909091| 4.627659574468085|7.870967741935484|             53.58|            14.91|             31.5|\n",
      "|           8|2.0458715596330275| 4.553191489361702| 8.64516129032258|             56.71|            13.42|            29.87|\n",
      "|           9|2.3518518518518516| 4.574468085106383|7.903225806451613|             53.29|            15.86|            30.85|\n",
      "|          10|2.2844036697247705| 4.494623655913978| 8.67741935483871|             56.14|            14.78|            29.08|\n",
      "|          11| 2.290909090909091|               4.5| 8.64516129032258|             56.01|            14.84|            29.15|\n",
      "|          12|2.3394495412844036|4.6063829787234045|8.483870967741936|             54.98|            15.16|            29.85|\n",
      "|          13|2.3873873873873874| 4.531914893617022|9.193548387096774|             57.06|            14.82|            28.13|\n",
      "|          14| 2.272727272727273| 4.212765957446808|8.258064516129032|             56.01|            15.42|            28.57|\n",
      "|          15|2.5137614678899083| 4.617021276595745| 8.96774193548387|             55.71|            15.61|            28.68|\n",
      "|          16|               2.3| 4.585106382978723|8.741935483870968|             55.94|            14.72|            29.34|\n",
      "|          17|2.4234234234234235| 4.319148936170213|7.935483870967742|             54.06|            16.51|            29.43|\n",
      "|          18|2.6486486486486487|  4.75531914893617| 8.35483870967742|             53.02|            16.81|            30.18|\n",
      "|          19|2.5636363636363635|4.3936170212765955|7.161290322580645|             50.72|            18.16|            31.12|\n",
      "+------------+------------------+------------------+-----------------+------------------+-----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Utilizando este nuevo DF, crea 3 columnas nuevas que hagan referencia a qué porcentaje \n",
    "#de la suma de \"espanolesmujeres\" en los tres distritos para cada rango de edad representa \n",
    "#cada uno de los tres distritos. Debe estar redondeada a 2 decimales. Puedes imponerte la \n",
    "#condición extra de no apoyarte en ninguna columna auxiliar creada para el caso.\n",
    "\n",
    "porcentaje = col('BARAJAS') + col('CENTRO') + col('RETIRO')\n",
    "\n",
    "padron_p = (pivot_df\n",
    "                    .withColumn('Barajas Porcentaje', round(col('BARAJAS')/ porcentaje*100, 2))\n",
    "                    .withColumn('Centro Porcentaje', round(col('CENTRO')/ porcentaje*100, 2))\n",
    "                    .withColumn('Retiro Porcentaje', round(col('RETIRO')/ porcentaje*100, 2))\n",
    "                    )\n",
    "                                \n",
    "padron_p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0f4e80a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o813.save.\n: org.apache.spark.SparkException: Job aborted.\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:231)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:188)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)\r\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z\r\n\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)\r\n\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)\r\n\tat org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)\r\n\tat org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:332)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:402)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:375)\r\n\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:182)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:220)\r\n\t... 32 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-0e2a245a7d54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# para ver la estructura de los ficheros y comprueba que es la esperada\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'padronSpark/padronCsv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m (partition.write\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DESC_DISTRITO'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DESC_BARRIO'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\python\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[0;32m   1107\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1109\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0msince\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 raise Py4JJavaError(\n\u001b[0m\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o813.save.\n: org.apache.spark.SparkException: Job aborted.\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:231)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:188)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)\r\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z\r\n\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)\r\n\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)\r\n\tat org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)\r\n\tat org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:332)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:402)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:375)\r\n\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:182)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:220)\r\n\t... 32 more\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b276181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda el archivo csv original particionado por distrito y por barrio en un directorio local. Consulta el directorio\n",
    "# para ver la estructura de los ficheros y comprueba que es la esperada\n",
    "file = 'padronSpark/padronCsv'\n",
    "(partition.write\n",
    "    .partitionBy('DESC_DISTRITO', 'DESC_BARRIO')\n",
    "    .format('csv')\n",
    "    .mode('overwrite')\n",
    "    .save(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b548b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En parquet\n",
    "file = 'padronSpark/padronParquet'\n",
    "(partition.write\n",
    "    .partitionBy('DESC_DISTRITO', 'DESC_BARRIO')\n",
    "    .parquet(file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
